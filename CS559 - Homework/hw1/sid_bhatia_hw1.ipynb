{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS559 - Homework #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Sid Bhatia\n",
    "\n",
    "**Date**: September 7th, 2024\n",
    "\n",
    "**Pledge**: I pledge my honor that I have abided by the Stevens Honor System.\n",
    "\n",
    "**Professor**: Dr. In Suk Jang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Regression Modification [40 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, the linear regression algorithm, `Linear_Regression(learning_rate, iteration)`, was implemented to solve a weight vector in a gradient descent fashion. In this assignment, we will modify the linear regression that optimizes the weights via stochastic gradient descent and predict the house price of the unit area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Load the provided data set as follows.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./Realestate.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Realestate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. [5pts] Standardize the data using each featureâ€™s mean $\\mu$ and standard deviation $\\sigma_i$ as shown below:\n",
    "\n",
    "$$\n",
    "x_{i, \\text{std}} = \\frac{x_i - \\mu_i}{\\sigma_i}\n",
    "$$\n",
    "\n",
    "where $i$ is the feature index. Standardize the target variable as well. The standardized data set will be used for the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No  X1 transaction date  X2 house age  \\\n",
      "0   1             2012.917          32.0   \n",
      "1   2             2012.917          19.5   \n",
      "2   3             2013.583          13.3   \n",
      "3   4             2013.500          13.3   \n",
      "4   5             2012.833           5.0   \n",
      "\n",
      "   X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
      "0                                84.87882                               10   \n",
      "1                               306.59470                                9   \n",
      "2                               561.98450                                5   \n",
      "3                               561.98450                                5   \n",
      "4                               390.56840                                5   \n",
      "\n",
      "   X5 latitude  X6 longitude  Y house price of unit area  \n",
      "0     24.98298     121.54024                        37.9  \n",
      "1     24.98034     121.53951                        42.2  \n",
      "2     24.98746     121.54391                        47.3  \n",
      "3     24.98746     121.54391                        54.8  \n",
      "4     24.97937     121.54245                        43.1  \n",
      "['No', 'X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude', 'Y house price of unit area']\n",
      "Y house price of unit area\n"
     ]
    }
   ],
   "source": [
    "# View overhead of DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Retrieve column names and parse as a list\n",
    "col_names = df.columns.values.tolist()\n",
    "\n",
    "# View column names\n",
    "print(col_names)\n",
    "\n",
    "# Retrieve target variable name\n",
    "target = col_names[-1]\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         No  X1 transaction date  X2 house age  \\\n",
      "0 -1.725784            -0.822688      1.254111   \n",
      "1 -1.717427            -0.822688      0.156896   \n",
      "2 -1.709069             1.539289     -0.387322   \n",
      "3 -1.700712             1.244928     -0.387322   \n",
      "4 -1.692355            -1.120595     -1.115873   \n",
      "\n",
      "   X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
      "0                               -0.791537                         2.004982   \n",
      "1                               -0.615866                         1.665488   \n",
      "2                               -0.413515                         0.307513   \n",
      "3                               -0.413515                         0.307513   \n",
      "4                               -0.549332                         0.307513   \n",
      "\n",
      "   X5 latitude  X6 longitude  Y house price of unit area  \n",
      "0     1.124070      0.448220                   -0.005894  \n",
      "1     0.911342      0.400654                    0.310132  \n",
      "2     1.485063      0.687352                    0.684953  \n",
      "3     1.485063      0.687352                    1.236161  \n",
      "4     0.833180      0.592220                    0.376277  \n",
      "0   -0.005894\n",
      "1    0.310132\n",
      "2    0.684953\n",
      "3    1.236161\n",
      "4    0.376277\n",
      "Name: Y house price of unit area, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = df.drop(columns=['Y house price of unit area'])\n",
    "target = df['Y house price of unit area']\n",
    "\n",
    "# Standardized features and target\n",
    "features_stand = (features - features.mean()) / features.std()\n",
    "\n",
    "target_stand = (target - target.mean()) / target.std()\n",
    "\n",
    "# print(features_stand.head())\n",
    "\n",
    "# df_merged = features_stand.append(target_stand) DEPRECIATED\n",
    "\n",
    "df_stand = pd.concat([features_stand, target_stand.rename('Y house price of unit area')], axis = 1)\n",
    "\n",
    "print(df_stand.head())\n",
    "print(target_stand.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. [5pts] Using `Scikit-Learn Linear Regression`, predict the target and report the Root Mean Square Error Value (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 0.7125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define feature and target variable\n",
    "X = df_stand[['X2 house age', 'X3 distance to the nearest MRT station']]\n",
    "y = df_stand[['Y house price of unit area']]\n",
    "\n",
    "# Create Linear Regression model and fit it\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit Linear Regression model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Establish y_hat to predict on training set\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Retrieve mean squared error\n",
    "mse = mean_squared_error(y, y_hat)\n",
    "\n",
    "# Calculate root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Using the `NumPy Linear_Regression()` implemented in the lecture, predict the target and report the RMSE value. Tune learning rate $\\eta$ and the iteration number so the RMSE value is not more than $10\\%$ of the RMSE value from the Scikit-learn Linear Regression result. Report the final RMSE and $\\eta$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_regression():\n",
    "    \n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    # Model Training Function\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        # Number of training example, Number of features\n",
    "        self.m, self.n = X.shape \n",
    "        \n",
    "        # Weight initialization\n",
    "        \n",
    "        self.W = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # Gradient Descent Learning    \n",
    "        for i in range(self.iterations):\n",
    "            self.update_weights()\n",
    "        return self\n",
    "    \n",
    "    # Function to update weights in Gradient Descent\n",
    "    def update_weights(self):\n",
    "        Y_pred = self.predict(self.X)\n",
    "        \n",
    "        # Gradient calculations\n",
    "        dW = - (2 * (self.X.T).dot(self.Y - Y_pred)) / self.m\n",
    "        db = - 2 * np.sum(self.Y - Y_pred) / self.m\n",
    "        \n",
    "        # Weight updates\n",
    "        self.W = self.W - self.learning_rate * dW\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        \n",
    "        return self\n",
    "    # Hypthetical Function\n",
    "    def predict(self, X):\n",
    "        \n",
    "        return X.dot(self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange variables to fit Linear_regression()\n",
    "x1 = np.array(df_stand['X2 house age'])\n",
    "x2 = np.array(df_stand['X3 distance to the nearest MRT station'])\n",
    "\n",
    "y = np.array(target_stand)\n",
    "\n",
    "X = np.column_stack([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [-0.19343469 -0.66865666]\n",
      "b = -6.972415130496186e-18\n",
      "Final RMSE = 0.7125\n"
     ]
    }
   ],
   "source": [
    "model = Linear_regression(learning_rate = 0.005, iterations=10000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "h_hat = model.predict(X)\n",
    "\n",
    "# Print the learned weights and bias\n",
    "print(f'W = {model.W}')\n",
    "print(f'b = {model.b}')\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y, h_hat)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Final RMSE = {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. [20pts] Modify the `Linear_regression()` algorithm that estimates the weights in a **stochastic gradient descent** manner. Report the RMSE value. Start with the $\\eta$ found from (d) and tune the parameters until the RMSE value is within $10\\%$ of the RMSE found from (c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_regression():\n",
    "    \n",
    "    def __init__(self, learning_rate, iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    # Model Training Function\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        # Number of training example, Number of features\n",
    "        self.m, self.n = X.shape \n",
    "        \n",
    "        # Weight initialization\n",
    "        \n",
    "        self.W = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # Stochastic Gradient Descent    \n",
    "        for i in range(self.iterations):\n",
    "\n",
    "            # Shuffle the data.\n",
    "            indices = np.random.permutation(self.m)\n",
    "            X_shuffled = self.X[indices]\n",
    "            Y_shuffled = self.Y[indices]\n",
    "\n",
    "            # Iterate through each sample.\n",
    "            for j in range(self.m):\n",
    "                self.update_weights(X_shuffled[j], Y_shuffled[j])\n",
    "        return self\n",
    "    \n",
    "    # Function to update weights in Gradient Descent\n",
    "    def update_weights(self, X_sample, Y_sample):\n",
    "        Y_pred = self.predict(X_sample)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        dW = -2 * (X_sample.T * (Y_sample - Y_pred))  # Gradient of weight\n",
    "        db = -2 * (Y_sample - Y_pred)  # Gradient of bias\n",
    "        \n",
    "        # Update weights and bias\n",
    "        self.W = self.W - self.learning_rate * dW\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Hypthetical Function\n",
    "    def predict(self, X):\n",
    "        return X.dot(self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange variables to fit Linear_regression().\n",
    "x1 = np.array(df_stand['X2 house age'])\n",
    "x2 = np.array(df_stand['X3 distance to the nearest MRT station'])\n",
    "\n",
    "y = np.array(target_stand)\n",
    "\n",
    "X = np.column_stack([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [-0.20245669 -0.63883477]\n",
      "b = -0.019426865108235394\n",
      "Final RMSE = 0.7134\n"
     ]
    }
   ],
   "source": [
    "model = Linear_regression(learning_rate = 0.002, iterations=10000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "h_hat = model.predict(X)\n",
    "\n",
    "# Print the learned weights and bias\n",
    "print(f'W = {model.W}')\n",
    "print(f'b = {model.b}')\n",
    "\n",
    "# Calculate RMSE\n",
    "mse = mean_squared_error(y, h_hat)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Final RMSE = {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Bayesian Theorem [15pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y\n",
      "0  1  1\n",
      "1  0  0\n",
      "2  0  0\n",
      "3  1  0\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. [5pts] Calculate a prior probability of $x$ and $y$, $p(x = 0), p(x = 1), p(y = 0)$ and $p(y = 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y\n",
      "0  1  1\n",
      "1  0  0\n",
      "2  0  0\n",
      "3  1  0\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "data = {'X': [1, 0, 0, 1, 1],\n",
    "        'Y': [1, 0, 0, 0, 0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior probabilities\n",
    "p_x_0 = len(df[df['X'] == 0]) / len(df)\n",
    "\n",
    "print(p_x_0)\n",
    "\n",
    "p_x_1 = len(df[df['X'] == 1]) / len(df)\n",
    "\n",
    "print(p_x_1)\n",
    "\n",
    "p_y_0 = len(df[df['Y'] == 0]) / len(df)\n",
    "\n",
    "print(p_y_0)\n",
    "\n",
    "p_y_1 = len(df[df['Y'] == 1]) / len(df)\n",
    "\n",
    "print(p_y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. [5pts] Calculate the likelihood of $x$, $p(x = 0 \\mid y = 0), p(x = 1 \\mid y = 0), p(x = 0 \\mid y = 1)$, and $p(x = 1 \\mid y = 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the likelihoods\n",
    "p_x_0_given_y_0 = len(df[(df['X'] == 0) & (df['Y'] == 0)]) / len(df[df['Y'] == 0])\n",
    "\n",
    "print(p_x_0_given_y_0)\n",
    "\n",
    "p_x_1_given_y_0 = len(df[(df['X'] == 1) & (df['Y'] == 0)]) / len(df[df['Y'] == 0])\n",
    "\n",
    "print(p_x_1_given_y_0)\n",
    "\n",
    "p_x_0_given_y_1 = len(df[(df['X'] == 0) & (df['Y'] == 1)]) / len(df[df['Y'] == 1])\n",
    "\n",
    "print(p_x_0_given_y_1)\n",
    "\n",
    "p_x_1_given_y_1 = len(df[(df['X'] == 1) & (df['Y'] == 1)]) / len(df[df['Y'] == 1])\n",
    "\n",
    "print(p_x_1_given_y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. [5pts] Calculate the posterior probabilities, $p(y = 1 \\mid x = 0), p(y = 0 \\mid x = 0), p(y = 1 \\mid x = 1)$, and $p(y = 0 \\mid x = 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.33333333333333337\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculating posteriors using Bayes' Theorem\n",
    "p_y_1_given_x_0 = (p_x_0_given_y_1 * p_y_1) / p_x_0\n",
    "\n",
    "print(p_y_1_given_x_0)\n",
    "\n",
    "p_y_0_given_x_0 = (p_x_0_given_y_0 * p_y_0) / p_x_0\n",
    "\n",
    "print(p_y_0_given_x_0)\n",
    "\n",
    "p_y_1_given_x_1 = (p_x_1_given_y_1 * p_y_1) / p_x_1\n",
    "\n",
    "print(p_y_1_given_x_1)\n",
    "\n",
    "p_y_0_given_x_1 = (p_x_1_given_y_0 * p_y_0) / p_x_1\n",
    "\n",
    "print(p_y_0_given_x_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. LDA [45pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary LDA classification of $\\bf{X}^{2 \\times 2}$ was solved by finding the direction of the projection hyperplane $(\\mathbf{w \\propto S^{-1}_w(m_2 - m_1)})$ in the lecture. In this problem, the binary LDA classification model will be trained and the train model will generalize the test data. Please display the results for full credit consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data set and split it into train and test sets.\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples = 100, n_features = 4, centers = 2, cluster_std = 1.5, random_state = 123)\n",
    "\n",
    "y = np.array([-1 if i == 0 else 1 for i in y])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples = 100, n_features = 4, centers = 2, cluster_std = 1.5, random_state = 123)\n",
    "\n",
    "y = np.array([-1 if i == 0 else 1 for i in y])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. [10pts] Write a method that computes the between-class scatter matrix $\\bf{S}_B$. Compute $\\bf{S}_B$ using a train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.42177386e+00 -1.48370842e+01 -7.83733634e+01 -1.38981884e+01]\n",
      " [-1.48370842e+01  1.54834094e+02  8.17874222e+02  1.45036139e+02]\n",
      " [-7.83733634e+01  8.17874222e+02  4.32022577e+03  7.66118860e+02]\n",
      " [-1.38981884e+01  1.45036139e+02  7.66118860e+02  1.35858203e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Method to compute the between-class scatter matrix S_B\n",
    "def compute_S_B(X_train, y_train):\n",
    "    # Compute the class means\n",
    "    class_labels = np.unique(y_train)\n",
    "    mean_vectors = [np.mean(X_train[y_train == label], axis=0) for label in class_labels]\n",
    "    \n",
    "    # Overall mean\n",
    "    overall_mean = np.mean(X_train, axis=0)\n",
    "    \n",
    "    # Compute between-class scatter matrix S_B\n",
    "    S_B = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "    for i, mean_vec in enumerate(mean_vectors):\n",
    "        n = X_train[y_train == class_labels[i]].shape[0]  # Number of samples in class\n",
    "        mean_diff = (mean_vec - overall_mean).reshape(-1, 1)\n",
    "        S_B += n * (mean_diff @ mean_diff.T)  # Accumulate the scatter\n",
    "\n",
    "    return S_B\n",
    "\n",
    "# Compute the between-class scatter matrix S_B\n",
    "S_B = compute_S_B(X_train, y_train)\n",
    "\n",
    "print(S_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. [10pts] Write a method that computes and returns the within-class scatter of each class, the total-within class scatter ($\\bf{S}_w$), and its inverse ($\\bf{S}^{-1}_w$). Calculate $\\bf{S}_w$ and $S^{-1}_w$ using the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189.11331817   6.52860091 -16.42044417   8.18216257]\n",
      " [  6.52860091 204.02423606  -2.00586952   5.86496479]\n",
      " [-16.42044417  -2.00586952 154.61882164   2.54574474]\n",
      " [  8.18216257   5.86496479   2.54574474 147.72968011]]\n",
      "\n",
      "\n",
      "[[ 5.35588997e-03 -1.57131974e-04  5.71698050e-04 -3.00255075e-04]\n",
      " [-1.57131974e-04  4.91228014e-03  5.01215342e-05 -1.87181528e-04]\n",
      " [ 5.71698050e-04  5.01215342e-05  6.53128940e-03 -1.46204087e-04]\n",
      " [-3.00255075e-04 -1.87181528e-04 -1.46204087e-04  6.79570108e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Method to compute the within-class scatter matrix S_w and its inverse S_w_inv\n",
    "def compute_S_w(X_train, y_train):\n",
    "    # Compute the class means\n",
    "    class_labels = np.unique(y_train)\n",
    "    \n",
    "    # Initialize the within-class scatter matrix S_w\n",
    "    S_w = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "    \n",
    "    # Compute within-class scatter for each class\n",
    "    for label in class_labels:\n",
    "        class_scatter = np.cov(X_train[y_train == label], rowvar=False) * (len(X_train[y_train == label]) - 1)\n",
    "        S_w += class_scatter  # Accumulate the scatter for each class\n",
    "\n",
    "    # Calculate the inverse of the within-class scatter matrix\n",
    "    S_w_inv = np.linalg.inv(S_w)\n",
    "    \n",
    "    return S_w, S_w_inv\n",
    "\n",
    "# Compute the within-class scatter matrix S_w and its inverse S_w_inv using the training data\n",
    "S_w, S_w_inv = compute_S_w(X_train, y_train)\n",
    "\n",
    "print(S_w)\n",
    "print(\"\\n\")\n",
    "print(S_w_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. [10pts] `NumPy.linalg.eig()` estimates eigenvalues $\\lambda$ and their corresponding eigenvectors $\\bf{u}$. Using `NumPy.linalg.eig()`,  find the direction of all projection planes, and transform the train data to each projection plane. Determine the most ideal $\\lambda$ and $\\bf{u}$ for the binary classification. Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00000000e+00,  2.96351674e+01, -3.58042237e-16,  1.60188508e-16]),\n",
       " array([[-0.99984555, -0.05874635,  0.1560219 , -0.17561664],\n",
       "        [-0.00250869, -0.14249608,  0.85218794, -0.41879989],\n",
       "        [-0.01718134, -0.97591602, -0.2365057 , -0.08123579],\n",
       "        [-0.00271783, -0.15437502,  0.439884  ,  0.88722387]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the matrix product of S_w_inv and S_B\n",
    "matrix_product = S_w_inv @ S_B\n",
    "\n",
    "# Compute eigenvalues and eigenvectors using numpy's linalg.eig()\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrix_product)\n",
    "\n",
    "# Display eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed training data:\n",
      "[-10.49344401  -8.23403937   6.23778243   5.08140446   6.72768436\n",
      " -10.93272746   6.64475407 -10.29143476   6.90063926   7.48667905\n",
      "  -9.20802779   4.20466442   5.59896819  -7.66837953   3.54573059\n",
      " -10.25743448   5.49893221   4.2407423    5.27944813   5.34346907\n",
      " -11.11043834   4.91767919   6.66868634   6.90746514  -9.60594471\n",
      "  -7.52798134  -7.2455161   -9.15383918   4.6228364    8.92768934\n",
      "   1.94799768  -8.9249959  -12.15341543  -9.43776759   3.08870353\n",
      "  -9.56730677   3.61019215   4.89304479  -8.39122099   3.51991109\n",
      "  -9.41591469  -8.87569777 -11.22517511   4.29068917   3.95598145\n",
      "  -8.67028721 -10.60203636 -11.52335963   5.18338783   7.30538879\n",
      " -10.33219259   5.94491653   6.18164718   5.80082771   7.14751497\n",
      " -11.99170186  -9.88351589 -10.12535624   6.28384107  -8.9039398\n",
      " -12.81448959 -10.37107446 -10.56376386   4.60320796  -9.58593198\n",
      "   5.26765969   3.30152767  -7.96083662   7.36595707   5.11734733\n",
      "   4.96162237 -11.23722769  -9.08314793   2.78198007   3.59642149\n",
      "   4.97050172   6.13612752 -10.58224325 -11.25597717  -9.37977532]\n"
     ]
    }
   ],
   "source": [
    "projection_vector = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "X_train_transformed = X_train @ projection_vector\n",
    "\n",
    "print(\"Transformed training data:\")\n",
    "print(X_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalue $\\lambda = 29.64$ is the largest positive eigenvalue, which results in the largest variance between two classes in the projected direction. Therefore, it's the best for binary classification.\n",
    "\n",
    "The corresponding eigenvector $u = [-0.0587, -0.1425, -0.9759, -0.1544]$ represents the direction of the projection plane which maximizes the separation between two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. [5pts] Using a choice of $\\bf{u}$ from 3(c), predict the class of train data and calculate the accuracy score using the `from sklearn.metrics import accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Choosing the eigenvector corresponding to the largest eigenvalue\n",
    "best_u = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "\n",
    "# Project the training data onto this eigenvector\n",
    "X_train_projection = X_train @ best_u\n",
    "\n",
    "# Predict the classes: if projection > 0, classify as 1; otherwise, classify as -1\n",
    "y_train_pred = np.where(X_train_projection > 0, 1, -1)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. [5pts] Predict the class of train data using other $\\bf{u}$ vectors in 3(c) and calculate the accuracy. Based on the results of 3(c) and 3(d), explain if your choice of $\\bf{u}$ is the correct decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_1': 0.525, 'u_2': 0.475, 'u_3': 0.5375}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the eigenvectors\n",
    "other_us = [eigenvectors[:, i] for i in range(len(eigenvalues)) if i != np.argmax(eigenvalues)]\n",
    "\n",
    "# Dictionary to store accuracy scores for each eigenvector\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Loop through each of the other eigenvectors and calculate accuracy\n",
    "for i, u in enumerate(other_us):\n",
    "    X_train_projection_other = X_train @ u \n",
    "    threshold_other = np.mean(X_train_projection_other)\n",
    "    y_train_pred_other = np.where(X_train_projection_other > threshold_other, 1, -1)\n",
    "    accuracy = accuracy_score(y_train, y_train_pred_other)\n",
    "    accuracy_scores[f'u_{i+1}'] = accuracy\n",
    "\n",
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest eigenvalue chosen in 3(d) resulted in an accuracy score of $0\\%$ which indicates while the corresponding eigenvector corresponds to the best direction of separating the classes based on variance, the overlap between the projections of the classes prevents effective classification with a basic threshold.\n",
    "\n",
    "Therefore, the eigenvector corresponding to $\\bf{u}_3$ turns out to be the best for classification based on the accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
